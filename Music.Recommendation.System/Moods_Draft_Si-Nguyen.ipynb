{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open('audio_lyrics_moods_new.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>mode</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>lyrics_features</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.912744</td>\n",
       "      <td>0.083704</td>\n",
       "      <td>132.069</td>\n",
       "      <td>0.293137</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>218.30667</td>\n",
       "      <td>-3.890</td>\n",
       "      <td>0.752186</td>\n",
       "      <td>0.726920</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.541</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>oppa gangnam style gangnam style najeneun ttas...</td>\n",
       "      <td>[energetic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.745704</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>100.008</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.012727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>235.06086</td>\n",
       "      <td>-7.687</td>\n",
       "      <td>0.351282</td>\n",
       "      <td>0.691817</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.796</td>\n",
       "      <td>1.000</td>\n",
       "      <td>late ve ve lose sleep dream thing babi ve ve p...</td>\n",
       "      <td>[happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.231455</td>\n",
       "      <td>130.030</td>\n",
       "      <td>0.121741</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>232.46104</td>\n",
       "      <td>-5.150</td>\n",
       "      <td>0.374390</td>\n",
       "      <td>0.704729</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.000</td>\n",
       "      <td>parti rock yeah woo let s parti rock hous toni...</td>\n",
       "      <td>[cocky, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.705822</td>\n",
       "      <td>0.053292</td>\n",
       "      <td>126.009</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194.09333</td>\n",
       "      <td>-3.898</td>\n",
       "      <td>0.592798</td>\n",
       "      <td>0.875137</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.742</td>\n",
       "      <td>alagamun lan weh wakun heya hanun gon alagamun...</td>\n",
       "      <td>[energetic, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.741757</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>129.985</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.096732</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>285.42667</td>\n",
       "      <td>-5.860</td>\n",
       "      <td>0.585630</td>\n",
       "      <td>0.730711</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.822</td>\n",
       "      <td>1.000</td>\n",
       "      <td>j lo s new generat mr worldwid parti peopl flo...</td>\n",
       "      <td>[energetic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key    energy  liveliness    tempo  speechiness  acousticness  \\\n",
       "0  11.0  0.912744    0.083704  132.069     0.293137      0.005423   \n",
       "1   6.0  0.745704    0.119955  100.008     0.046255      0.026230   \n",
       "2   5.0  0.709932    0.231455  130.030     0.121741      0.036662   \n",
       "3   3.0  0.705822    0.053292  126.009     0.126016      0.001966   \n",
       "4   3.0  0.741757    0.072774  129.985     0.051255      0.096732   \n",
       "\n",
       "   instrumentalness  time_signature  duration   loudness  valence  \\\n",
       "0          0.000001             0.0       4.0  218.30667   -3.890   \n",
       "1          0.012727             1.0       4.0  235.06086   -7.687   \n",
       "2          0.000000             0.0       4.0  232.46104   -5.150   \n",
       "3          0.000000             0.0       4.0  194.09333   -3.898   \n",
       "4          0.000474             0.0       4.0  285.42667   -5.860   \n",
       "\n",
       "   danceability      mode  time_signature_confidence  tempo_confidence  \\\n",
       "0      0.752186  0.726920                      0.552             0.541   \n",
       "1      0.351282  0.691817                      0.737             0.634   \n",
       "2      0.374390  0.704729                      0.565             0.565   \n",
       "3      0.592798  0.875137                      0.004             0.114   \n",
       "4      0.585630  0.730711                      0.271             0.324   \n",
       "\n",
       "   key_confidence  mode_confidence  \\\n",
       "0           1.000            1.000   \n",
       "1           0.796            1.000   \n",
       "2           0.743            1.000   \n",
       "3           1.000            0.742   \n",
       "4           0.822            1.000   \n",
       "\n",
       "                                     lyrics_features               moods  \n",
       "0  oppa gangnam style gangnam style najeneun ttas...         [energetic]  \n",
       "1  late ve ve lose sleep dream thing babi ve ve p...             [happy]  \n",
       "2  parti rock yeah woo let s parti rock hous toni...      [cocky, happy]  \n",
       "3  alagamun lan weh wakun heya hanun gon alagamun...  [energetic, happy]  \n",
       "4  j lo s new generat mr worldwid parti peopl flo...         [energetic]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizing (estimator, param_grid, train_test_list, n_jobs):\n",
    "    \n",
    "    output = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_list\n",
    "    \n",
    "    grid = GridSearchCV(estimator, param_grid, refit = True, n_jobs = n_jobs)\n",
    "    grid.fit(X_train, y_train) \n",
    "    \n",
    "    output['estimator'] = grid.best_estimator_\n",
    "    output['params'] = grid.best_params_\n",
    "    output['prediction'] = grid.predict(X_test)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def estimator_searching (init_classifiers, param_grids, train_test_list, n_jobs):\n",
    "    \n",
    "    classifiers = {method : {} for method in init_classifiers.keys()}\n",
    "    \n",
    "    for method in classifiers.keys():\n",
    "        \n",
    "        estimator = init_classifiers [method]\n",
    "        param_grid = param_grids [method]\n",
    "        \n",
    "        classifiers[method] = optimizing(estimator, param_grid, train_test_list, n_jobs)\n",
    "    \n",
    "    return classifiers\n",
    "\n",
    "def show_selected_params (classifiers, train_test_list):\n",
    "        \n",
    "    y_true = train_test_list[3]\n",
    "        \n",
    "    for model, result in classifiers.items():\n",
    "        print(\"    Classification report of {} model:\".format(model)) \n",
    "        print(classification_report(y_true, result['prediction']))\n",
    "        print(\" ...with selected params: {} \\n\".format(result['params']))\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>mode</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.912744</td>\n",
       "      <td>0.083704</td>\n",
       "      <td>132.069</td>\n",
       "      <td>0.293137</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>218.30667</td>\n",
       "      <td>-3.890</td>\n",
       "      <td>0.752186</td>\n",
       "      <td>0.726920</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.541</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[energetic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.745704</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>100.008</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.012727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>235.06086</td>\n",
       "      <td>-7.687</td>\n",
       "      <td>0.351282</td>\n",
       "      <td>0.691817</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.796</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.231455</td>\n",
       "      <td>130.030</td>\n",
       "      <td>0.121741</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>232.46104</td>\n",
       "      <td>-5.150</td>\n",
       "      <td>0.374390</td>\n",
       "      <td>0.704729</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[cocky, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.705822</td>\n",
       "      <td>0.053292</td>\n",
       "      <td>126.009</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194.09333</td>\n",
       "      <td>-3.898</td>\n",
       "      <td>0.592798</td>\n",
       "      <td>0.875137</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.742</td>\n",
       "      <td>[energetic, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.741757</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>129.985</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.096732</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>285.42667</td>\n",
       "      <td>-5.860</td>\n",
       "      <td>0.585630</td>\n",
       "      <td>0.730711</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.822</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[energetic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key    energy  liveliness    tempo  speechiness  acousticness  \\\n",
       "0  11.0  0.912744    0.083704  132.069     0.293137      0.005423   \n",
       "1   6.0  0.745704    0.119955  100.008     0.046255      0.026230   \n",
       "2   5.0  0.709932    0.231455  130.030     0.121741      0.036662   \n",
       "3   3.0  0.705822    0.053292  126.009     0.126016      0.001966   \n",
       "4   3.0  0.741757    0.072774  129.985     0.051255      0.096732   \n",
       "\n",
       "   instrumentalness  time_signature  duration   loudness  valence  \\\n",
       "0          0.000001             0.0       4.0  218.30667   -3.890   \n",
       "1          0.012727             1.0       4.0  235.06086   -7.687   \n",
       "2          0.000000             0.0       4.0  232.46104   -5.150   \n",
       "3          0.000000             0.0       4.0  194.09333   -3.898   \n",
       "4          0.000474             0.0       4.0  285.42667   -5.860   \n",
       "\n",
       "   danceability      mode  time_signature_confidence  tempo_confidence  \\\n",
       "0      0.752186  0.726920                      0.552             0.541   \n",
       "1      0.351282  0.691817                      0.737             0.634   \n",
       "2      0.374390  0.704729                      0.565             0.565   \n",
       "3      0.592798  0.875137                      0.004             0.114   \n",
       "4      0.585630  0.730711                      0.271             0.324   \n",
       "\n",
       "   key_confidence  mode_confidence               moods  \n",
       "0           1.000            1.000         [energetic]  \n",
       "1           0.796            1.000             [happy]  \n",
       "2           0.743            1.000      [cocky, happy]  \n",
       "3           1.000            0.742  [energetic, happy]  \n",
       "4           0.822            1.000         [energetic]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_moods = df.drop('lyrics_features', axis = 1)\n",
    "audio_moods.dropna(how = 'any', inplace = True)\n",
    "audio_moods.reset_index(drop = True, inplace = True)\n",
    "audio_moods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlb_audio = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_audio = mlb_audio.fit_transform(audio_moods['moods'])\n",
    "y_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30296, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cocky', 'earthy', 'energetic', 'happy', 'sad', 'seductive',\n",
       "       'spacey'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_audio.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>mode</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.912744</td>\n",
       "      <td>0.083704</td>\n",
       "      <td>132.069</td>\n",
       "      <td>0.293137</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>218.30667</td>\n",
       "      <td>-3.890</td>\n",
       "      <td>0.752186</td>\n",
       "      <td>0.726920</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.541</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.745704</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>100.008</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.012727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>235.06086</td>\n",
       "      <td>-7.687</td>\n",
       "      <td>0.351282</td>\n",
       "      <td>0.691817</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.796</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>0.231455</td>\n",
       "      <td>130.030</td>\n",
       "      <td>0.121741</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>232.46104</td>\n",
       "      <td>-5.150</td>\n",
       "      <td>0.374390</td>\n",
       "      <td>0.704729</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.705822</td>\n",
       "      <td>0.053292</td>\n",
       "      <td>126.009</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194.09333</td>\n",
       "      <td>-3.898</td>\n",
       "      <td>0.592798</td>\n",
       "      <td>0.875137</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.741757</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>129.985</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.096732</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>285.42667</td>\n",
       "      <td>-5.860</td>\n",
       "      <td>0.585630</td>\n",
       "      <td>0.730711</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.822</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key    energy  liveliness    tempo  speechiness  acousticness  \\\n",
       "0  11.0  0.912744    0.083704  132.069     0.293137      0.005423   \n",
       "1   6.0  0.745704    0.119955  100.008     0.046255      0.026230   \n",
       "2   5.0  0.709932    0.231455  130.030     0.121741      0.036662   \n",
       "3   3.0  0.705822    0.053292  126.009     0.126016      0.001966   \n",
       "4   3.0  0.741757    0.072774  129.985     0.051255      0.096732   \n",
       "\n",
       "   instrumentalness  time_signature  duration   loudness  valence  \\\n",
       "0          0.000001             0.0       4.0  218.30667   -3.890   \n",
       "1          0.012727             1.0       4.0  235.06086   -7.687   \n",
       "2          0.000000             0.0       4.0  232.46104   -5.150   \n",
       "3          0.000000             0.0       4.0  194.09333   -3.898   \n",
       "4          0.000474             0.0       4.0  285.42667   -5.860   \n",
       "\n",
       "   danceability      mode  time_signature_confidence  tempo_confidence  \\\n",
       "0      0.752186  0.726920                      0.552             0.541   \n",
       "1      0.351282  0.691817                      0.737             0.634   \n",
       "2      0.374390  0.704729                      0.565             0.565   \n",
       "3      0.592798  0.875137                      0.004             0.114   \n",
       "4      0.585630  0.730711                      0.271             0.324   \n",
       "\n",
       "   key_confidence  mode_confidence  \n",
       "0           1.000            1.000  \n",
       "1           0.796            1.000  \n",
       "2           0.743            1.000  \n",
       "3           1.000            0.742  \n",
       "4           0.822            1.000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = audio_moods.drop('moods', axis = 1)\n",
    "X_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30296, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_audio = np.array(X_1)\n",
    "X_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_train_test_list = train_test_split(X_audio, y_audio, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators= 100, class_weight='balanced')\n",
    "rfc.fit(audio_train_test_list[0], audio_train_test_list[2])\n",
    "\n",
    "rfc_prediction = rfc.predict(audio_train_test_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.06      0.11      1611\n",
      "          1       0.67      0.14      0.24      1905\n",
      "          2       0.62      0.07      0.12      1661\n",
      "          3       0.59      0.25      0.36      3225\n",
      "          4       0.61      0.25      0.35      2279\n",
      "          5       0.51      0.04      0.07      1945\n",
      "          6       0.63      0.15      0.24      1690\n",
      "\n",
      "avg / total       0.60      0.15      0.23     14316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(audio_train_test_list[3], rfc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rfc, open('audio_predict_moods.rfc.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_init_classifiers = {\n",
    "        'rfc': RandomForestClassifier(class_weight='balanced')\n",
    "    }\n",
    "\n",
    "audio_param_grids = {    \n",
    "    'rfc': \n",
    "    {\n",
    "        'n_estimators': [5, 10, 50, 100],\n",
    "        'min_samples_split': [2, 3, 4, 5, 10],\n",
    "        'max_features': ['sqrt', 'log2', 'auto']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_rfc = estimator_searching(audio_init_classifiers, audio_param_grids, audio_train_test_list, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Classification report of rfc model:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.16      0.24      1611\n",
      "          1       0.54      0.21      0.30      1905\n",
      "          2       0.41      0.16      0.23      1661\n",
      "          3       0.51      0.28      0.36      3225\n",
      "          4       0.51      0.30      0.37      2279\n",
      "          5       0.38      0.13      0.19      1945\n",
      "          6       0.50      0.24      0.33      1690\n",
      "\n",
      "avg / total       0.48      0.22      0.30     14316\n",
      "\n",
      " ...with selected params: {'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 10} \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_selected_params(audio_rfc, audio_train_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cocky', 'earthy', 'energetic', 'happy', 'sad', 'seductive',\n",
       "       'spacey'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_audio.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(RandomForestClassifier(class_weight='balanced', n_estimators=100),\n",
    "                                n_jobs = 2)\n",
    "\n",
    "audio_chain = ClassifierChain(estimator, \n",
    "                              order=[4, 5, 6, 0, 2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.15      0.24      1611\n",
      "          1       0.42      0.43      0.43      1905\n",
      "          2       0.57      0.15      0.24      1661\n",
      "          3       0.46      0.65      0.54      3225\n",
      "          4       0.60      0.25      0.35      2279\n",
      "          5       0.53      0.07      0.12      1945\n",
      "          6       0.62      0.19      0.29      1690\n",
      "\n",
      "avg / total       0.53      0.31      0.34     14316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_chain.fit(audio_train_test_list[0], audio_train_test_list[2])\n",
    "audio_chain_prediction = audio_chain.predict(audio_train_test_list[1])\n",
    "\n",
    "print(classification_report(audio_train_test_list[3], audio_chain_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_chain_init_classifiers = {\n",
    "        'chain_rfc': ClassifierChain(RandomForestClassifier(class_weight='balanced'))\n",
    "    }\n",
    "\n",
    "audio_chain_param_grids = {    \n",
    "    'chain_rfc': \n",
    "    {\n",
    "        'base_estimator__n_estimators': [5, 10, 50, 100],\n",
    "        'base_estimator__max_features': ['sqrt', 'log2', 'auto'],\n",
    "        'order': [[4, 5, 6, 0, 2, 3, 1], [4, 5, 6, 1, 3, 2, 0]]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_chain_optimized = estimator_searching(audio_chain_init_classifiers, \n",
    "                                            audio_chain_param_grids, \n",
    "                                            audio_train_test_list, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Classification report of chain_rfc model:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.15      0.24      1611\n",
      "          1       0.44      0.43      0.43      1905\n",
      "          2       0.55      0.15      0.23      1661\n",
      "          3       0.46      0.67      0.55      3225\n",
      "          4       0.61      0.26      0.37      2279\n",
      "          5       0.53      0.07      0.12      1945\n",
      "          6       0.62      0.20      0.30      1690\n",
      "\n",
      "avg / total       0.53      0.32      0.35     14316\n",
      "\n",
      " ...with selected params: {'base_estimator__max_features': 'sqrt', 'base_estimator__n_estimators': 100, 'order': [4, 5, 6, 0, 2, 3, 1]} \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_selected_params(audio_chain_optimized, audio_train_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = OneVsRestClassifier(RandomForestClassifier(class_weight='balanced', n_estimators=100),\n",
    "                                n_jobs = 2)\n",
    "\n",
    "audio_chain = ClassifierChain(estimator, \n",
    "                              order=[4, 5, 6, 1, 3, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.40      0.40      1611\n",
      "          1       0.55      0.30      0.39      1905\n",
      "          2       0.50      0.22      0.30      1661\n",
      "          3       0.48      0.60      0.53      3225\n",
      "          4       0.60      0.25      0.35      2279\n",
      "          5       0.56      0.07      0.13      1945\n",
      "          6       0.63      0.19      0.29      1690\n",
      "\n",
      "avg / total       0.53      0.32      0.36     14316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_chain.fit(audio_train_test_list[0], audio_train_test_list[2])\n",
    "audio_chain_prediction = audio_chain.predict(audio_train_test_list[1])\n",
    "\n",
    "print(classification_report(audio_train_test_list[3], audio_chain_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Classification report of chain_logreg model:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.35      0.35      1611\n",
      "          1       0.32      0.43      0.36      1905\n",
      "          2       0.29      0.70      0.41      1661\n",
      "          3       0.45      0.35      0.39      3225\n",
      "          4       0.40      0.66      0.50      2279\n",
      "          5       0.30      0.62      0.41      1945\n",
      "          6       0.28      0.69      0.40      1690\n",
      "\n",
      "avg / total       0.35      0.53      0.41     14316\n",
      "\n",
      " ...with selected params: {'base_estimator__multi_class': 'ovr', 'order': [4, 5, 6, 1, 3, 2, 0]} \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_chain_init_classifiers = {\n",
    "        'chain_logreg': ClassifierChain(LogisticRegression(class_weight='balanced'))\n",
    "    }\n",
    "\n",
    "audio_chain_param_grids = {    \n",
    "    'chain_logreg': \n",
    "    {\n",
    "        'base_estimator__multi_class': ['ovr'],\n",
    "        'order': [[4, 5, 6, 0, 2, 3, 1], [4, 5, 6, 1, 3, 2, 0]]\n",
    "    }\n",
    "}\n",
    "\n",
    "audio_chain_optimized = estimator_searching(audio_chain_init_classifiers, \n",
    "                                            audio_chain_param_grids, \n",
    "                                            audio_train_test_list, n_jobs=3)\n",
    "\n",
    "show_selected_params(audio_chain_optimized, audio_train_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['estimator__C', 'estimator__cache_size', 'estimator__class_weight', 'estimator__coef0', 'estimator__decision_function_shape', 'estimator__degree', 'estimator__gamma', 'estimator__kernel', 'estimator__max_iter', 'estimator__probability', 'estimator__random_state', 'estimator__shrinking', 'estimator__tol', 'estimator__verbose', 'estimator', 'n_jobs'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr_svm = OneVsRestClassifier(SVC(class_weight='balanced'))\n",
    "ovr_svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_chain_init_classifiers = {\n",
    "        'chain_svm': Pipeline([('scaler', MinMaxScaler()), \n",
    "                               ('clf', ClassifierChain(ovr_svm))\n",
    "                              ])\n",
    "    }\n",
    "\n",
    "audio_chain_param_grids = {    \n",
    "    'chain_svm': \n",
    "    {\n",
    "        'clf__base_estimator__estimator__C': [0.1, 1],\n",
    "        'clf__base_estimator__estimator__gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'clf__order': [[4, 5, 6, 1, 3, 2, 0]]\n",
    "    }\n",
    "}\n",
    "\n",
    "audio_chain_optimized = estimator_searching(audio_chain_init_classifiers, \n",
    "                                            audio_chain_param_grids, \n",
    "                                            audio_train_test_list, n_jobs=3)\n",
    "\n",
    "show_selected_params(audio_chain_optimized, audio_train_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "audio_voter = VotingClassifier(estimators= [('chain', audio_chain), ('rfc', rfc)],\n",
    "                              voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Multilabel and multi-output classification is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1b88fdd3d976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maudio_voter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_train_test_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_train_test_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maudio_voter_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_voter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_train_test_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_train_test_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_voter_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             raise NotImplementedError('Multilabel and multi-output'\n\u001b[0m\u001b[1;32m    150\u001b[0m                                       ' classification is not supported.')\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Multilabel and multi-output classification is not supported."
     ]
    }
   ],
   "source": [
    "audio_voter.fit(audio_train_test_list[0], audio_train_test_list[2])\n",
    "audio_voter_prediction = audio_voter.predict(audio_train_test_list[1])\n",
    "\n",
    "print(classification_report(audio_train_test_list[3], audio_voter_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20930, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lyrics_features</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oppa gangnam style gangnam style najeneun ttas...</td>\n",
       "      <td>[energetic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>late ve ve lose sleep dream thing babi ve ve p...</td>\n",
       "      <td>[happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>parti rock yeah woo let s parti rock hous toni...</td>\n",
       "      <td>[cocky, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>alagamun lan weh wakun heya hanun gon alagamun...</td>\n",
       "      <td>[energetic, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>j lo s new generat mr worldwid parti peopl flo...</td>\n",
       "      <td>[energetic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                    lyrics_features  \\\n",
       "0      0  oppa gangnam style gangnam style najeneun ttas...   \n",
       "1      1  late ve ve lose sleep dream thing babi ve ve p...   \n",
       "2      2  parti rock yeah woo let s parti rock hous toni...   \n",
       "3      3  alagamun lan weh wakun heya hanun gon alagamun...   \n",
       "4      4  j lo s new generat mr worldwid parti peopl flo...   \n",
       "\n",
       "                moods  \n",
       "0         [energetic]  \n",
       "1             [happy]  \n",
       "2      [cocky, happy]  \n",
       "3  [energetic, happy]  \n",
       "4         [energetic]  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_moods = df.loc[df['lyrics_features'] != \"\", ['lyrics_features', 'moods']].copy()\n",
    "\n",
    "lyrics_moods.reset_index(inplace = True)\n",
    "\n",
    "print(lyrics_moods.shape)\n",
    "lyrics_moods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlb_lyrics = MultiLabelBinarizer()\n",
    "\n",
    "y_lyrics = mlb_lyrics.fit_transform(lyrics_moods['moods'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cocky', 'earthy', 'energetic', 'happy', 'sad', 'seductive',\n",
       "       'spacey'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_lyrics.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20930, 7)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lyrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyrics_train_test_list = train_test_split(lyrics_moods['lyrics_features'], y_lyrics, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyrics_pipeline = Pipeline([ ('tf_idf', TfidfVectorizer()), \n",
    "                            ('clf', RandomForestClassifier(n_estimators=10, class_weight='balanced')) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tf_idf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pipeline.fit(lyrics_train_test_list[0], lyrics_train_test_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lyrics_pipeline.predict(lyrics_train_test_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.05      0.09      1254\n",
      "          1       0.26      0.01      0.03      1080\n",
      "          2       0.48      0.03      0.06      1109\n",
      "          3       0.46      0.14      0.21      2145\n",
      "          4       0.48      0.06      0.11      1472\n",
      "          5       0.46      0.05      0.10      1089\n",
      "          6       0.42      0.03      0.05       878\n",
      "\n",
      "avg / total       0.44      0.07      0.11      9027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lyrics_train_test_list[3], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyrics_chain = Pipeline([ ('tf_idf', TfidfVectorizer()), \n",
    "                         ('clf', ClassifierChain(RandomForestClassifier(class_weight='balanced'), \n",
    "                                                 order=[4, 5, 6, 1, 3, 2, 0])) \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.09      0.15      1254\n",
      "          1       0.33      0.04      0.08      1080\n",
      "          2       0.37      0.09      0.14      1109\n",
      "          3       0.48      0.26      0.33      2145\n",
      "          4       0.40      0.07      0.13      1472\n",
      "          5       0.45      0.08      0.14      1089\n",
      "          6       0.33      0.02      0.04       878\n",
      "\n",
      "avg / total       0.41      0.11      0.17      9027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics_chain.fit(lyrics_train_test_list[0], lyrics_train_test_list[2])\n",
    "lyrics_chain_prediction = lyrics_chain.predict(lyrics_train_test_list[1])\n",
    "\n",
    "print(classification_report(lyrics_train_test_list[3], lyrics_chain_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tf_idf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...    verbose=0, warm_start=False),\n",
       "        cv=None, order=[4, 5, 6, 1, 3, 2, 0], random_state=None))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_chain_svd = Pipeline([ ('tf_idf', TfidfVectorizer()), ('svd', TruncatedSVD(n_components=500)),\n",
    "                         ('clf', ClassifierChain(RandomForestClassifier(class_weight='balanced'), \n",
    "                                                 order=[4, 5, 6, 1, 3, 2, 0])) \n",
    "                        ])\n",
    "\n",
    "lyrics_chain_svd.fit(lyrics_train_test_list[0], lyrics_train_test_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.13      0.18      1254\n",
      "          1       0.28      0.02      0.04      1080\n",
      "          2       0.32      0.05      0.08      1109\n",
      "          3       0.42      0.16      0.23      2145\n",
      "          4       0.40      0.05      0.09      1472\n",
      "          5       0.46      0.05      0.09      1089\n",
      "          6       0.33      0.02      0.03       878\n",
      "\n",
      "avg / total       0.37      0.08      0.12      9027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics_chain_svd_prediction = lyrics_chain_svd.predict(lyrics_train_test_list[1])\n",
    "\n",
    "print(classification_report(lyrics_train_test_list[3], lyrics_chain_svd_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec.load('./song_lyrics.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_train = doc2vec_model[lyrics_train_test_list[0].index]\n",
    "doc2vec_test = doc2vec_model[lyrics_train_test_list[1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14651, 100)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.03      0.06      1254\n",
      "          1       0.16      0.00      0.01      1080\n",
      "          2       0.29      0.01      0.02      1109\n",
      "          3       0.43      0.09      0.15      2145\n",
      "          4       0.35      0.03      0.06      1472\n",
      "          5       0.25      0.01      0.02      1089\n",
      "          6       0.25      0.00      0.01       878\n",
      "\n",
      "avg / total       0.33      0.04      0.06      9027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc2vec_rfc = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "doc2vec_rfc.fit(doc2vec_train, lyrics_train_test_list[2])\n",
    "\n",
    "print(classification_report(lyrics_train_test_list[3], doc2vec_rfc.predict(doc2vec_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.18      0.21      1254\n",
      "          1       0.31      0.05      0.08      1080\n",
      "          2       0.32      0.04      0.08      1109\n",
      "          3       0.42      0.26      0.33      2145\n",
      "          4       0.42      0.06      0.11      1472\n",
      "          5       0.35      0.02      0.03      1089\n",
      "          6       0.45      0.01      0.02       878\n",
      "\n",
      "avg / total       0.37      0.11      0.15      9027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc2vec_chain = ClassifierChain(RandomForestClassifier(class_weight='balanced'),\n",
    "                                order=[4, 5, 6, 1, 3, 2, 0])\n",
    "\n",
    "doc2vec_chain.fit(doc2vec_train, lyrics_train_test_list[2])\n",
    "\n",
    "print(classification_report(lyrics_train_test_list[3], doc2vec_chain.predict(doc2vec_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
